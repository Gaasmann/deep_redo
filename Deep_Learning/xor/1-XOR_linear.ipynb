{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning XOR function with linear regression\n",
    "## Deep Learning, 6.1, p. 166\n",
    "\n",
    "The book demonstrates that a linear regression can't approximate the XOR function.\n",
    "The resolution of the normal equations shows that the weights = 0 and bias = 0.5\n",
    "\n",
    "Here I implement the linear regression and apply gradient descent in order to see if it comes to the same conclusion (and to play with TensorFlow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_path = \"./logs-nb1\"\n",
    "data = np.array([[0,0],[0,1],[1,0],[1,1]], np.float32)\n",
    "label = np.array([0,1,1,0],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Imported data\n",
    "with tf.name_scope(\"Inputs\"):\n",
    "    tf_data = tf.constant(data, name=\"data\")\n",
    "    tf_label = tf.constant(label, shape=(4,1), name=\"labels\")\n",
    "# Variables\n",
    "with tf.name_scope(\"Weights\"):\n",
    "    weights = tf.Variable(tf.truncated_normal([2, 1], dtype=tf.float32), name=\"weights_out\")\n",
    "with tf.name_scope(\"Bias\"):\n",
    "    bias = tf.Variable(tf.zeros([], dtype=tf.float32), name=\"bias_out\")\n",
    "# layer\n",
    "with tf.name_scope(\"Output_layer\"):\n",
    "    output = tf.matmul(tf_data, weights) + bias\n",
    "# loss function\n",
    "with tf.name_scope(\"Loss_function\"):\n",
    "    loss = tf.reduce_mean(tf.pow(tf_label - output, 2), 0)\n",
    "# Gradient descent\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(log_path)\n",
    "tf.summary.scalar(\"loss\", loss[0])\n",
    "tf.summary.scalar(\"weight_1\", weights[0][0])\n",
    "tf.summary.scalar(\"weight_2\", weights[1][0])\n",
    "tf.summary.scalar(\"bias\", bias)\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: [ 0.57297945], weight: [[-0.46463761]\n",
      " [ 0.69079763]], bias: 0.0\n",
      "step 100, loss: [ 0.25236216], weight: [[ 0.00350409]\n",
      " [ 0.09538115]], bias: 0.44135409593582153\n",
      "step 200, loss: [ 0.2500619], weight: [[ 0.00651335]\n",
      " [ 0.01381917]], bias: 0.48794135451316833\n",
      "step 300, loss: [ 0.25000238], weight: [[ 0.00179989]\n",
      " [ 0.00238083]], bias: 0.4975205361843109\n",
      "step 400, loss: [ 0.25000012], weight: [[ 0.00040671]\n",
      " [ 0.0004529 ]], bias: 0.4994902014732361\n",
      "step 500, loss: [ 0.25], weight: [[  8.65065595e-05]\n",
      " [  9.01836102e-05]], bias: 0.49989524483680725\n",
      "step 600, loss: [ 0.24999999], weight: [[  1.80163570e-05]\n",
      " [  1.83123211e-05]], bias: 0.4999784827232361\n",
      "step 700, loss: [ 0.25], weight: [[  3.73359353e-06]\n",
      " [  3.75835998e-06]], bias: 0.49999552965164185\n",
      "step 800, loss: [ 0.25], weight: [[  7.87634349e-07]\n",
      " [  7.88558509e-07]], bias: 0.4999990463256836\n",
      "step 900, loss: [ 0.25], weight: [[  3.12286971e-07]\n",
      " [  3.11720981e-07]], bias: 0.4999995529651642\n",
      "step 1000, loss: [ 0.24999997], weight: [[  2.97385753e-07]\n",
      " [  2.96819763e-07]], bias: 0.4999995529651642\n"
     ]
    }
   ],
   "source": [
    "nb_steps = 1001\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(nb_steps):\n",
    "        _, l, w, b, summary = session.run([optimizer, loss, weights, bias, summary_op])\n",
    "        writer.add_summary(summary, step)\n",
    "        if step % 100 == 0:\n",
    "            print(\"step {}, loss: {}, weight: {}, bias: {}\".format(step, l, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final values:\n",
      "Loss: 0.25\n",
      "Weights: 0.00 0.00\n",
      "Bias: 0.50\n"
     ]
    }
   ],
   "source": [
    "print(\"Final values:\")\n",
    "print(\"Loss: {:.2f}\".format(l[0]))\n",
    "print(\"Weights: {:.2f} {:.2f}\".format(w[0][0],w[1][0]))\n",
    "print(\"Bias: {:.2f}\".format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
